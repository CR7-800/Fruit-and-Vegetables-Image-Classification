---
title: Fruit and Vegetables Image Classification
emoji: ğŸ¦€
colorFrom: yellow
colorTo: green
sdk: streamlit
sdk_version: 1.42.2
app_file: app.py
pinned: false
---

# Fruit and Vegetables Image Classification

## è³‡æ–™ä¾†æº
åŒ…å«å¤šç¨®æ°´æœåœ–åƒçš„è³‡æ–™é›†ï¼Œé©åˆç”¨æ–¼åœ–åƒåˆ†é¡å’Œè¨ˆç®—æ©Ÿè¦–è¦ºä»»å‹™  

[Fruits and Vegetables Image Recognition Dataset](https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition/data)

### è³‡æ–™é›†
è³‡æ–™é›†åŒ…å«å¤šç¨®æ°´æœå’Œè”¬èœçš„åœ–ç‰‡ï¼Œåˆ†ç‚ºè¨“ç·´ã€æ¸¬è©¦å’Œé©—è­‰ä¸‰å€‹éƒ¨åˆ†ã€‚  
æ¯å€‹éƒ¨åˆ†çš„åœ–ç‰‡è·¯å¾‘åœ¨ `label_dict.json` ä¸­æœ‰è©³ç´°è¨˜éŒ„ã€‚

### é æ¸¬
ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹ï¼Œåœ¨ `app.py` ä¸­å»ºç«‹äº†ä¸€å€‹ Streamlit æ‡‰ç”¨ï¼Œå…è¨±ä½¿ç”¨è€…ä¸Šå‚³åœ–ç‰‡ä¸¦é€²è¡Œæ°´æœèˆ‡è”¬èœè¾¨è­˜ã€‚    
è©²æ‡‰ç”¨å·²éƒ¨ç½²æ–¼ **Hugging Face Spaces**ï¼Œç„¡éœ€æ‰‹å‹•ä¸‹è¼‰ç¨‹å¼ä¸¦åŸ·è¡Œï¼Œå¯ç›´æ¥åœ¨ç·šä¸Šæ¸¬è©¦ã€‚
ğŸ‘‰ [**é»æ­¤ä½¿ç”¨**](https://huggingface.co/spaces/CR7-800/Fruit-and-Vegetables-Image-Classification)



## ç›®éŒ„
1. [æ›è¼‰ Google Drive](#1æ›è¼‰-google-drive)
2. [åŒ¯å…¥å¿…è¦æ¨¡çµ„å’Œå‡½å¼åº«](#2åŒ¯å…¥å¿…è¦æ¨¡çµ„å’Œå‡½å¼åº«)
3. [ç²å–å½±åƒæª”æ¡ˆè·¯å¾‘](#3ç²å–å½±åƒæª”æ¡ˆè·¯å¾‘)
4. [å»ºç«‹å½±åƒè·¯å¾‘èˆ‡æ¨™ç±¤çš„ DataFrame](#4å»ºç«‹å½±åƒè·¯å¾‘èˆ‡æ¨™ç±¤çš„-dataframe)
5. [åˆ†æèˆ‡è¦–è¦ºåŒ–å„é¡åˆ¥çš„æ¨£æœ¬æ•¸é‡åˆ†å¸ƒ](#5åˆ†æèˆ‡è¦–è¦ºåŒ–å„é¡åˆ¥çš„æ¨£æœ¬æ•¸é‡åˆ†å¸ƒ)
6. [é¡¯ç¤ºæ¯å€‹é¡åˆ¥çš„ç¬¬ä¸€å¼µåœ–åƒ](#6é¡¯ç¤ºæ¯å€‹é¡åˆ¥çš„ç¬¬ä¸€å¼µåœ–åƒ)
7. [å‰µå»ºå½±åƒæ•¸æ“šç”Ÿæˆå™¨é€²è¡Œæ•¸æ“šå¢å¼·å’Œé è™•ç†](#7å‰µå»ºå½±åƒæ•¸æ“šç”Ÿæˆå™¨é€²è¡Œæ•¸æ“šå¢å¼·å’Œé è™•ç†)
8. [è¼‰å…¥ä¸¦é…ç½®é è¨“ç·´æ¨¡å‹ MobileNetV2](#8è¼‰å…¥ä¸¦é…ç½®é è¨“ç·´æ¨¡å‹-mobilenetv2)
9. [å»ºç«‹ä¸¦è¨“ç·´å½±åƒåˆ†é¡æ¨¡å‹](#9å»ºç«‹ä¸¦è¨“ç·´å½±åƒåˆ†é¡æ¨¡å‹)
10. [è¦–è¦ºåŒ–æ¨¡å‹è¨“ç·´éç¨‹ä¸­çš„æº–ç¢ºç‡å’Œæå¤±](#10è¦–è¦ºåŒ–æ¨¡å‹è¨“ç·´éç¨‹ä¸­çš„æº–ç¢ºç‡å’Œæå¤±)
11. [ç²å–ä¸¦é¡¯ç¤ºæ¨™ç±¤å°æ‡‰è¡¨](#11ç²å–ä¸¦é¡¯ç¤ºæ¨™ç±¤å°æ‡‰è¡¨)
12. [è¼‰å…¥æœ€ä½³æ¨¡å‹ä¸¦ä½¿ç”¨æ¸¬è©¦æ•¸æ“šé€²è¡Œé æ¸¬](#12è¼‰å…¥æœ€ä½³æ¨¡å‹ä¸¦ä½¿ç”¨æ¸¬è©¦æ•¸æ“šé€²è¡Œé æ¸¬)
13. [é¡¯ç¤ºæ··æ·†çŸ©é™£](#13é¡¯ç¤ºæ··æ·†çŸ©é™£)
14. [Hugging Face Spaces æ‡‰ç”¨](#14hugging-face-spaces-æ‡‰ç”¨)
15. [çµè«–](#15çµè«–)



### 1.æ›è¼‰ Google Drive
```python
from google.colab import drive
drive.mount('/content/drive')
```



### 2.åŒ¯å…¥å¿…è¦æ¨¡çµ„å’Œå‡½å¼åº«
```python
import numpy as np
import pandas as pd
import os.path
import matplotlib.pyplot as plt
import tensorflow as tf
import seaborn as sns
import sys

from pathlib import Path
from collections import Counter
from PIL import Image
from tensorflow.keras import layers, models
from tensorflow.keras import optimizers
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay

print('pythonç‰ˆæœ¬:',sys.version)
print('tensorflowç‰ˆæœ¬:',tf.__version__)
```



### 3.ç²å–å½±åƒæª”æ¡ˆè·¯å¾‘
- å®šç¾© get_image_filepaths() å‡½å¼ï¼Œç²å–æŒ‡å®šç›®éŒ„å…§æ‰€æœ‰ .jpg å½±åƒæª”æ¡ˆè·¯å¾‘
```python
# å®šç¾©å‡½å¼ä¾†ç²å–æŒ‡å®šç›®éŒ„ä¸­çš„æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
def get_image_filepaths(directory):
    return list(Path(directory).glob(r'**/*.jpg'))

# ç²å–æ‰€æœ‰åœ–åƒè·¯å¾‘
train_filepaths = get_image_filepaths('/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/Fruit-and-Vegetables-Image-Classification-main/train')
test_filepaths = get_image_filepaths('/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/Fruit-and-Vegetables-Image-Classification-main/test')
val_filepaths = get_image_filepaths('/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/Fruit-and-Vegetables-Image-Classification-main/validation')
```



### 4.å»ºç«‹å½±åƒè·¯å¾‘èˆ‡æ¨™ç±¤çš„ DataFrame
- å®šç¾© proc_img() å‡½å¼ï¼Œå¾å½±åƒè·¯å¾‘æå–æ¨™ç±¤ï¼Œä¸¦å»ºç«‹ DataFrameã€‚
```python
# è™•ç†åœ–åƒè·¯å¾‘ä»¥å‰µå»º DataFrame
def proc_img(filepaths):
    data = []
    for filepath in filepaths:
        label = filepath.parent.name # æ¨™ç±¤æ˜¯è³‡æ–™å¤¾åç¨±
        data.append({'Filepath':str(filepath),'Label':label})
    return pd.DataFrame(data)

# å¾åœ–åƒè·¯å¾‘ç”¢ç”Ÿè¨“ç·´ã€æ¸¬è©¦å’Œé©—è­‰è³‡æ–™é›†çš„DataFrame
train_df = proc_img(train_filepaths)
test_df = proc_img(test_filepaths)
val_df = proc_img(val_filepaths)

# æ‰“äº‚æ¸¬è©¦é›†ï¼Œç¢ºä¿æ¨¡å‹è©•ä¼°æ™‚å…¬å¹³
test_df = test_df.sample(frac=1).reset_index(drop=True)

# ç¢ºä¿DataFrameæ­£ç¢º
print("Training set samples:")
print(train_df.head(3))
print("\nTesting set samples:")
print(test_df.head(3))
print("\nValidation set samples:")
print(val_df.head(3))
```
åŸ·è¡Œçµæœ:     
![4 ç¢ºèª](https://github.com/user-attachments/assets/ea40ca6f-d427-4688-aaca-17bee2cd46b9)



### 5.åˆ†æèˆ‡è¦–è¦ºåŒ–å„é¡åˆ¥çš„æ¨£æœ¬æ•¸é‡åˆ†å¸ƒ
- ä½¿ç”¨ Counter è¨ˆç®— train_dfã€test_df å’Œ val_df ä¸­å„é¡åˆ¥çš„æ¨£æœ¬æ•¸é‡
- å»ºç«‹ DataFrame çµ±æ•´è¨“ç·´ã€æ¸¬è©¦èˆ‡é©—è­‰é›†çš„é¡åˆ¥æ¨£æœ¬åˆ†å¸ƒï¼Œä¸¦è¨ˆç®—ç¸½æ•¸
```python
# åˆ†ææ¯å€‹é¡åˆ¥çš„æ¨£æœ¬æ•¸é‡
train_label_counts = Counter(train_df['Label'])
test_label_counts = Counter(test_df['Label'])
val_label_counts = Counter(val_df['Label'])

# å‰µå»ºä¸€å€‹åŒ…å«æ¯å€‹é¡åˆ¥åœ¨å„æ•¸æ“šé›†ä¸­çš„æ¨£æœ¬æ•¸é‡çš„ DataFrame
label_distribution = pd.DataFrame({
    'Train':pd.Series(train_label_counts),
    'Test':pd.Series(test_label_counts),
    'Validation':pd.Series(val_label_counts)
}).fillna(0).astype(int)

# è¨ˆç®—ç¸½æ¨£æœ¬æ•¸
label_distribution['Total'] = label_distribution.sum(axis=1)
label_distribution = label_distribution.sort_values('Total',ascending=False)

# é¡¯ç¤ºé¡åˆ¥åˆ†å¸ƒçš„çµ±è¨ˆè³‡è¨Š
print("Number of categories:",len(label_distribution))
print("\nCategory distribution by sample count:")
print(label_distribution)

print("\nTotal samples per dataset:")
print(f"Training:{len(train_df)},Testing:{len(test_df)},Validation:{len(val_df)}")
print(f"Total samples:{len(train_df)+len(test_df)+len(val_df)}")

# è¦–è¦ºåŒ–é¡åˆ¥åˆ†å¸ƒçš„æ¢å½¢åœ–
plt.figure(figsize=(12,6))
sns.barplot(data=label_distribution.reset_index(),x="index",y="Total",color="skyblue")
plt.title('Distribution of Categories by Sample Count')
plt.xlabel('Category')
plt.ylabel('Number of Samples')
plt.xticks(rotation=45,ha='right')
plt.grid(axis='y',linestyle='--',alpha=0.7)
plt.show()
```
åŸ·è¡Œçµæœ:  
![5 è¦–è¦ºåŒ–](https://github.com/user-attachments/assets/4d9928f4-88bb-4a68-9431-555992a99452)
![5 è¦–è¦ºåŒ–(1)](https://github.com/user-attachments/assets/4b438120-4bd7-48f5-b89f-313e4da17dee)



### 6.é¡¯ç¤ºæ¯å€‹é¡åˆ¥çš„ç¬¬ä¸€å¼µåœ–åƒ
- å‰µå»ºä¸€å€‹å­—å…¸ä¾†å­˜å„²æ¯å€‹é¡åˆ¥çš„ç¬¬ä¸€å¼µå½±åƒï¼Œä¸¦ä½¿ç”¨ Matplotlib é¡¯ç¤ºé€™äº›å½±åƒ
```python
first_images = {}
for category in train_df['Label'].unique():
    first_images[category] = train_df[train_df['Label'] == category]['Filepath'].values[0]

plt.figure(figsize=(15,10))
for i, (category, image_path) in enumerate(first_images.items()):
    image = Image.open(image_path)
    plt.subplot(6,6,i+1) # i+1 æ˜¯å› ç‚º subplot å¾ 1 é–‹å§‹
    plt.imshow(image)
    plt.title(category)
    plt.axis('off')

plt.show()
```
åŸ·è¡Œçµæœ:  
![6 ç¬¬ä¸€å¼µåœ–](https://github.com/user-attachments/assets/a7d359f0-2943-43fb-9284-708b76b259dc)



### 7.å‰µå»ºå½±åƒæ•¸æ“šç”Ÿæˆå™¨é€²è¡Œæ•¸æ“šå¢å¼·å’Œé è™•ç† 
```python
# ä½¿ç”¨ ImageDataGenerator é€²è¡Œæ•¸æ“šå¢å¼·
train_datagen = ImageDataGenerator(
    rescale=1./255, # å°‡åƒç´ å€¼ç¸®æ”¾åˆ° [0, 1] ä¹‹é–“
    rotation_range=40, # éš¨æ©Ÿæ—‹è½‰åœ–ç‰‡
    width_shift_range=0.2, # éš¨æ©Ÿæ°´å¹³å¹³ç§»
    height_shift_range=0.2, # éš¨æ©Ÿå‚ç›´å¹³ç§»
    shear_range=0.2, # éš¨æ©Ÿå‰ªåˆ‡(æ²¿æŸå€‹æ–¹å‘å‚¾æ–œ)
    zoom_range=0.2, # éš¨æ©Ÿç¸®æ”¾
    horizontal_flip=True, # éš¨æ©Ÿæ°´å¹³ç¿»è½‰
    brightness_range=[0.8, 1.2], # éš¨æ©Ÿèª¿æ•´äº®åº¦
    channel_shift_range=0.2, # éš¨æ©Ÿæ”¹è®Šé¡è‰²é€šé“
    fill_mode='nearest' # å¡«å……æ–°å‰µå»ºåƒç´ çš„æ–¹æ³•
)

# å‰µå»º ImageDataGenerator ç”¨æ–¼é©—è­‰å’Œæ¸¬è©¦æ•¸æ“šé›†ï¼ˆä¸é€²è¡Œå¢å¼·ï¼‰
test_datagen = ImageDataGenerator(rescale=1./255)

# å‰µå»ºæ•¸æ“šç”Ÿæˆå™¨
train_generator = train_datagen.flow_from_dataframe(
    train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224,224),
    batch_size=32,
    class_mode='categorical' # ä½¿ç”¨ categorical_crossentropy æå¤±å‡½æ•¸
)

val_generator = test_datagen.flow_from_dataframe(
    val_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224,224),
    batch_size=32,
    class_mode='categorical'
)

# åœ¨å‰µå»ºæ•¸æ“šç”Ÿæˆå™¨ä¹‹å‰æ‰“äº‚æ•¸æ“šæ¡†
test_df = test_df.sample(frac=1).reset_index(drop=True)

# é‡æ–°å‰µå»ºæ•¸æ“šç”Ÿæˆå™¨
test_generator = test_datagen.flow_from_dataframe(
    test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224,224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)
```
åŸ·è¡Œçµæœ:  
![7 å¢å¼·](https://github.com/user-attachments/assets/01378b38-2d66-421b-bda7-700fc51965a2)



### 8.è¼‰å…¥ä¸¦é…ç½®é è¨“ç·´æ¨¡å‹ MobileNetV2
```python
# è¼‰å…¥é è¨“ç·´æ¨¡å‹
base_model = MobileNetV2(
    input_shape=(224,224,3), # è¼¸å…¥åœ–åƒçš„å½¢ç‹€
    include_top=False, # ä¸åŒ…å«é ‚å±¤çš„å…¨é€£æ¥å±¤
    weights='imagenet', # ä½¿ç”¨ ImageNet é è¨“ç·´æ¬Šé‡
    pooling='avg' # å…¨å±€å¹³å‡æ± åŒ–
)
base_model.trainable = False

# é¡¯ç¤ºæ¨¡å‹æ‘˜è¦
# base_model.summary()
```



### 9.å»ºç«‹ä¸¦è¨“ç·´å½±åƒåˆ†é¡æ¨¡å‹
```python
# å»ºç«‹æ¨¡å‹
input = base_model.input
x = layers.Dense(512,activation='relu')(base_model.output)
x = layers.Dense(256,activation='relu')(x)
x = layers.Dense(128,activation='relu')(x)
x = layers.Dense(64,activation='relu')(x)
output = layers.Dense(36,activation='softmax')(x)

model = models.Model(inputs=input,outputs=output)

# ç·¨è­¯æ¨¡å‹
model.compile(optimizer=optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# è¨­ç½®å›èª¿å‡½æ•¸
callbacks = [
    tf.keras.callbacks.ModelCheckpoint(
        filepath='/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/03_æ°´æœ/fruit_model.keras',
        save_best_only=True, # åªå„²å­˜æ€§èƒ½æœ€å¥½çš„æ¨¡å‹ï¼ˆæ ¹æ“šç›£æ§æŒ‡æ¨™ï¼‰
        monitor='val_accuracy', # ç›£æ§é©—è­‰é›†çš„æº–ç¢ºç‡
        mode='max' # ç•¶ val_accuracy æœ€å¤§æ™‚ï¼Œå„²å­˜æ¨¡å‹
    )
]

# è¨“ç·´æ¨¡å‹
history = model.fit(train_generator, # ä½¿ç”¨è¨“ç·´é›†æ•¸æ“š
                    validation_data=val_generator, # ä½¿ç”¨é©—è­‰é›†æ•¸æ“š
                    epochs=50,
                    callbacks=callbacks)
```
åŸ·è¡Œçµæœ:  
![è¨“ç·´](https://github.com/user-attachments/assets/2d5dc97d-1214-46fa-85df-953f4ad3aa80)



### 10.è¦–è¦ºåŒ–æ¨¡å‹è¨“ç·´éç¨‹ä¸­çš„æº–ç¢ºç‡å’Œæå¤±
- å°‡æ¨¡å‹è¨“ç·´éç¨‹ä¸­çš„æº–ç¢ºç‡å’Œæå¤±æ•¸æ“šè½‰æ›ç‚º DataFrame
- ä½¿ç”¨ Matplotlib ç¹ªè£½å‡ºè¨“ç·´å’Œé©—è­‰éç¨‹ä¸­çš„æº–ç¢ºç‡å’Œæå¤±æ›²ç·š 
```python
# å°‡è¨“ç·´æ­·å²è½‰æ›ç‚º DataFrame
result = pd.DataFrame(history.history)

# å‰µå»ºå­åœ–
fig, axes = plt.subplots(1,2,figsize=(15, 5))

# ç¹ªè£½æº–ç¢ºç‡æ›²ç·š
result[['accuracy','val_accuracy']].plot(ax=axes[0])
axes[0].set_title("Accuracy")
axes[0].set_xlabel("Epochs")
axes[0].set_ylabel("Accuracy")

# ç¹ªè£½æå¤±æ›²ç·š
result[['loss','val_loss']].plot(ax=axes[1])
axes[1].set_title("Loss")
axes[1].set_xlabel("Epochs")
axes[1].set_ylabel("Loss")

# èª¿æ•´ä½ˆå±€ä¸¦é¡¯ç¤ºåœ–è¡¨
plt.tight_layout()
plt.show()
```
åŸ·è¡Œçµæœ:  
![æº–ç¢ºç‡å’Œæå¤±](https://github.com/user-attachments/assets/e06b1f42-cd7d-4b66-938e-e72dffd4dd54)



### 11.ç²å–ä¸¦é¡¯ç¤ºæ¨™ç±¤å°æ‡‰è¡¨
```python
# ç²å–æ¨™ç±¤å°æ‡‰è¡¨
label_map = train_generator.class_indices

# åè½‰å­—å…¸ä»¥ä¾¿æ–¼æŸ¥è©¢
label_map = {v:k for k, v in label_map.items()}

# é¡¯ç¤ºæ¨™ç±¤å°æ‡‰è¡¨
print(label_map)
```
åŸ·è¡Œçµæœ:  
`{0: 'apple', 1: 'banana', 2: 'beetroot', 3: 'bell pepper', 4: 'cabbage', 5: 'capsicum', 6: 'carrot', 7: 'cauliflower', 8: 'chilli pepper', 9: 'corn', 10: 'cucumber', 11: 'eggplant', 12: 'garlic', 13: 'ginger', 14: 'grapes', 15: 'jalepeno', 16: 'kiwi', 17: 'lemon', 18: 'lettuce', 19: 'mango', 20: 'onion', 21: 'orange', 22: 'paprika', 23: 'pear', 24: 'peas', 25: 'pineapple', 26: 'pomegranate', 27: 'potato', 28: 'raddish', 29: 'soy beans', 30: 'spinach', 31: 'sweetcorn', 32: 'sweetpotato', 33: 'tomato', 34: 'turnip', 35: 'watermelon'}`



### 12.è¼‰å…¥æœ€ä½³æ¨¡å‹ä¸¦ä½¿ç”¨æ¸¬è©¦æ•¸æ“šé€²è¡Œé æ¸¬
```python
# è¼‰å…¥æœ€ä½³æ¨¡å‹
model = tf.keras.models.load_model('/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/03_æ°´æœ/fruit_model.keras')

# ä½¿ç”¨æ¸¬è©¦æ•¸æ“šç”Ÿæˆå™¨é€²è¡Œé æ¸¬
test_loss,test_accuracy = model.evaluate(test_generator)
print(f'Test accuracy:{test_accuracy * 100:.2f}%')

# ç²å–é æ¸¬çµæœ
predictions = model.predict(test_generator)
predicted_classes = np.argmax(predictions,axis=1)

# é¡¯ç¤ºå‰10å€‹é æ¸¬çµæœå’Œå¯¦éš›çµæœ
predicted_labels = [label_map[i] for i in predicted_classes[:10]]
actual_labels = [label_map[i] for i in test_generator.classes[:10]]

print("Predicted labels:",predicted_labels)
print("Actual labels:",actual_labels)
```
åŸ·è¡Œçµæœ:  
![æ¸¬è©¦é æ¸¬](https://github.com/user-attachments/assets/6146212c-e4a0-418e-b561-77953b6626f2)



### 13.é¡¯ç¤ºæ··æ·†çŸ©é™£
- è©•ä¼°æ¨¡å‹åœ¨æ¸¬è©¦æ•¸æ“šä¸Šçš„é æ¸¬æ•ˆæœ
```python
true_classes = test_generator.classes
pred_classes = predicted_classes

# ç”¢ç”Ÿæ··æ·†çŸ©é™£
cm = confusion_matrix(true_classes,pred_classes)

# é¡¯ç¤ºæ··æ·†çŸ©é™£
fig,ax = plt.subplots(figsize=(15,10))
disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=test_generator.class_indices.keys())
disp.plot(cmap=plt.cm.Blues,ax=ax)

# è‡ªå®šç¾©åœ–å½¢
plt.xticks(rotation=90)  # æ—‹è½‰ x è»¸æ¨™ç±¤ä»¥æé«˜å¯è®€æ€§
plt.title('Confusion Matrix')
plt.show()
```
åŸ·è¡Œçµæœ:  
![æ··æ·†çŸ©é™£](https://github.com/user-attachments/assets/e70ace2b-7764-4032-bfbf-a5b850e710a1)



### 14.Hugging Face Spaces æ‡‰ç”¨
- æœ¬å°ˆæ¡ˆçš„ Streamlit æ‡‰ç”¨å·²æˆåŠŸéƒ¨ç½²è‡³ Hugging Face Spaces 
- ä½ å¯ä»¥é€éä»¥ä¸‹é€£çµç›´æ¥ä½¿ç”¨æ‡‰ç”¨ï¼š[é»æ­¤é€²å…¥](https://huggingface.co/spaces/CR7-800/Fruit-and-Vegetables-Image-Classification)    
![è¾¨è­˜](https://github.com/user-attachments/assets/14953dea-faac-4738-90aa-4a7aeb258555)



### 15.çµè«–
åœ¨æœ¬å°ˆæ¡ˆä¸­ï¼Œæˆ‘å€‘æˆåŠŸåœ°å»ºç«‹äº†ä¸€å€‹åŸºæ–¼ `MobileNetV2` çš„å·ç©ç¥ç¶“ç¶²çµ¡æ¨¡å‹ï¼Œç”¨æ–¼è¾¨è­˜æ°´æœå’Œè”¬èœçš„åœ–åƒã€‚  
é€šéæ•¸æ“šå¢å¼·å’Œé è™•ç†ï¼Œæœ‰æ•ˆåœ°æå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚  
è¨“ç·´éç¨‹ä¸­ï¼Œä½¿ç”¨ `Kaggle` ä¸Šçš„ `Fruits and Vegetables Image Recognition Dataset`ï¼Œä¸¦åœ¨ `Google Colab` ä¸Šé€²è¡Œäº†æ¨¡å‹è¨“ç·´ã€‚

æ¨¡å‹åœ¨æ¸¬è©¦æ•¸æ“šé›†ä¸Šçš„æº–ç¢ºç‡é”åˆ°äº†ä»¤äººæ»¿æ„çš„æ°´å¹³ï¼Œä¸¦ä¸”é€šéæ··æ·†çŸ©é™£ï¼Œå¯ä»¥çœ‹åˆ°æ¨¡å‹åœ¨ä¸åŒé¡åˆ¥ä¸Šçš„é æ¸¬æ•ˆæœã€‚ 

æœªä¾†çš„æ”¹é€²æ–¹å‘å¯ä»¥åŒ…æ‹¬ï¼š
1. æ¢ç´¢å…¶ä»–é è¨“ç·´æ¨¡å‹ï¼Œå¦‚ EfficientNet æˆ– ResNetï¼Œä»¥é€²ä¸€æ­¥æå‡æ¨¡å‹æ€§èƒ½ã€‚
2. å¢åŠ æ•¸æ“šé›†çš„å¤šæ¨£æ€§ï¼ŒåŒ…å«æ›´å¤šä¸åŒèƒŒæ™¯å’Œå…‰ç…§æ¢ä»¶ä¸‹çš„åœ–åƒã€‚
3. å„ªåŒ–æ¨¡å‹è¶…åƒæ•¸ï¼Œé€²ä¸€æ­¥æå‡æº–ç¢ºç‡å’Œé™ä½æå¤±ã€‚
