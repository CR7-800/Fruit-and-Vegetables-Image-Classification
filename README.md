---
title: Fruit Image Classification
emoji: ğŸ¦€
colorFrom: yellow
colorTo: green
sdk: streamlit
sdk_version: 1.42.2
app_file: app.py
pinned: false
---

# Fruit and Vegetables Image Classification

## ç›®éŒ„
1. [æè¿°](#1æè¿°)
2. [åŒ¯å…¥å¿…è¦æ¨¡çµ„å’Œå‡½å¼åº«](#2åŒ¯å…¥å¿…è¦æ¨¡çµ„å’Œå‡½å¼åº«)
3. [ç²å–å½±åƒæª”æ¡ˆè·¯å¾‘ä¸¦è¨ˆç®—å½±åƒæ•¸é‡](#3ç²å–å½±åƒæª”æ¡ˆè·¯å¾‘ä¸¦è¨ˆç®—å½±åƒæ•¸é‡)
4. [è™•ç†å½±åƒæª”æ¡ˆè·¯å¾‘ä¸¦ç”Ÿæˆæ•¸æ“šæ¡†](#4è™•ç†å½±åƒæª”æ¡ˆè·¯å¾‘ä¸¦ç”Ÿæˆæ•¸æ“šæ¡†)
5. [ç²å–å½±åƒæ¨™ç±¤ä¸¦è¨ˆç®—è³‡æ–™é›†åˆ†ä½ˆ](#5ç²å–å½±åƒæ¨™ç±¤ä¸¦è¨ˆç®—è³‡æ–™é›†åˆ†ä½ˆ)
6. [é¡¯ç¤ºæ¯å€‹é¡åˆ¥çš„ç¬¬ä¸€å¼µåœ–åƒ](#6é¡¯ç¤ºæ¯å€‹é¡åˆ¥çš„ç¬¬ä¸€å¼µåœ–åƒ)
7. [å‰µå»ºå½±åƒæ•¸æ“šç”Ÿæˆå™¨é€²è¡Œæ•¸æ“šå¢å¼·å’Œé è™•ç†](#7å‰µå»ºå½±åƒæ•¸æ“šç”Ÿæˆå™¨é€²è¡Œæ•¸æ“šå¢å¼·å’Œé è™•ç†)
8. [è¼‰å…¥ä¸¦é…ç½®é è¨“ç·´æ¨¡å‹ MobileNetV2](#8è¼‰å…¥ä¸¦é…ç½®é è¨“ç·´æ¨¡å‹-mobilenetv2)
9. [å»ºç«‹ä¸¦è¨“ç·´å½±åƒåˆ†é¡æ¨¡å‹](#9å»ºç«‹ä¸¦è¨“ç·´å½±åƒåˆ†é¡æ¨¡å‹)
10. [è¦–è¦ºåŒ–æ¨¡å‹è¨“ç·´éç¨‹ä¸­çš„æº–ç¢ºç‡å’Œæå¤±](#10è¦–è¦ºåŒ–æ¨¡å‹è¨“ç·´éç¨‹ä¸­çš„æº–ç¢ºç‡å’Œæå¤±)
11. [ç²å–ä¸¦é¡¯ç¤ºæ¨™ç±¤å°æ‡‰è¡¨](#11ç²å–ä¸¦é¡¯ç¤ºæ¨™ç±¤å°æ‡‰è¡¨)
12. [è¼‰å…¥æœ€ä½³æ¨¡å‹ä¸¦ä½¿ç”¨æ¸¬è©¦æ•¸æ“šé€²è¡Œé æ¸¬](#12è¼‰å…¥æœ€ä½³æ¨¡å‹ä¸¦ä½¿ç”¨æ¸¬è©¦æ•¸æ“šé€²è¡Œé æ¸¬)
13. [é¡¯ç¤ºæ··æ·†çŸ©é™£](#13é¡¯ç¤ºæ··æ·†çŸ©é™£)
14. [Hugging Face Spaces æ‡‰ç”¨](#14hugging-face-spaces-æ‡‰ç”¨)
15. [çµè«–](#15çµè«–)



## 1.æè¿°
## ä½¿ç”¨å¾ Kaggle å–å¾—çš„æ°´æœå’Œè”¬èœåœ–åƒè­˜åˆ¥æ•¸æ“šé›†
## è³‡æ–™ä¾†æºï¼š[Fruits and Vegetables Image Recognition Dataset](https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition/data)  

é€é Kaggle ä¸Šçš„ Fruits and Vegetables Image Recognition Datasetï¼Œå»ºç«‹ä¸€å€‹æ¨¡å‹ä¾†è¾¨è­˜æ°´æœå’Œè”¬èœçš„åœ–ç‰‡ï¼Œä¸¦é€šéç¶²é æ‡‰ç”¨é€²è¡Œé æ¸¬ã€‚

### è³‡æ–™é›†
è³‡æ–™é›†åŒ…å«å¤šç¨®æ°´æœå’Œè”¬èœçš„åœ–ç‰‡ï¼Œåˆ†ç‚ºè¨“ç·´ã€æ¸¬è©¦å’Œé©—è­‰ä¸‰å€‹éƒ¨åˆ†ã€‚  
æ¯å€‹éƒ¨åˆ†çš„åœ–ç‰‡è·¯å¾‘åœ¨ `label_dict.json` ä¸­æœ‰è©³ç´°è¨˜éŒ„ã€‚

### æ¨¡å‹è¨“ç·´(åœ¨Google Colabä¸ŠåŸ·è¡Œ)
åœ¨ `fruit.ipynb` ä¸­ï¼Œä½¿ç”¨ TensorFlow å’Œ Keras è¨“ç·´äº†ä¸€å€‹å·ç©ç¥ç¶“ç¶²çµ¡ï¼ˆCNNï¼‰æ¨¡å‹ï¼Œ`fruit_model.keras`çš„è¨“ç·´éç¨‹åŒ…æ‹¬æ•¸æ“šå¢å¼·å’Œé è™•ç†ã€‚
```python
from google.colab import drive
drive.mount('/content/drive')
```

### é æ¸¬
ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹ï¼Œåœ¨ `app.py` ä¸­å»ºç«‹äº†ä¸€å€‹ Streamlit æ‡‰ç”¨ï¼Œå…è¨±ä½¿ç”¨è€…ä¸Šå‚³åœ–ç‰‡ä¸¦é€²è¡Œæ°´æœèˆ‡è”¬èœè¾¨è­˜ã€‚    
è©²æ‡‰ç”¨å·²éƒ¨ç½²æ–¼ **Hugging Face Spaces**ï¼Œç„¡éœ€æ‰‹å‹•ä¸‹è¼‰ç¨‹å¼ä¸¦åŸ·è¡Œï¼Œå¯ç›´æ¥åœ¨ç·šä¸Šæ¸¬è©¦ã€‚
ğŸ‘‰ [**é»æ­¤ä½¿ç”¨**](https://huggingface.co/spaces/CR7-800/fruit-image-classification)



## 2.åŒ¯å…¥å¿…è¦æ¨¡çµ„å’Œå‡½å¼åº«
```python
import numpy as np
import pandas as pd
import os.path
import matplotlib.pyplot as plt
import tensorflow as tf

from pathlib import Path
from collections import Counter
from PIL import Image
from tensorflow.keras import layers, models
from tensorflow.keras import optimizers
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
```


## 3.ç²å–å½±åƒæª”æ¡ˆè·¯å¾‘ä¸¦è¨ˆç®—å½±åƒæ•¸é‡
- å®šç¾©å‡½å¼ get_image_filepathsï¼Œç”¨æ–¼ç²å–æŒ‡å®šç›®éŒ„ä¸­æ‰€æœ‰ .jpg æ ¼å¼çš„å½±åƒæª”æ¡ˆè·¯å¾‘
- è¨ˆç®—è¨“ç·´ã€æ¸¬è©¦å’Œé©—è­‰è³‡æ–™é›†ä¸­å½±åƒçš„æ•¸é‡
```python
def get_image_filepaths(directory): # directory æ˜¯ä¸€å€‹ç”¨æ–¼æŒ‡å®šç›®éŒ„çš„è®Šæ•¸
    return list(Path(directory).glob(r'**/*.jpg'))

print('training images:',len(get_image_filepaths('/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/03_æ°´æœ/train')))
print('testing images:',len(get_image_filepaths('/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/03_æ°´æœ/test')))
print('validation images:',len(get_image_filepaths('/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/03_æ°´æœ/validation')))
```
åŸ·è¡Œçµæœ:  
![è¨ˆç®—å½±åƒæ•¸é‡](https://github.com/user-attachments/assets/841c2d01-c33a-40b7-ae97-504e85ae7856)



## 4.è™•ç†å½±åƒæª”æ¡ˆè·¯å¾‘ä¸¦ç”Ÿæˆæ•¸æ“šæ¡†
- å–å¾—è¨“ç·´ã€æ¸¬è©¦å’Œé©—è­‰è³‡æ–™é›†ä¸­æ‰€æœ‰å½±åƒçš„è·¯å¾‘
- å®šç¾©å‡½å¼ proc_imgï¼Œç”¨æ–¼è™•ç†é€™äº›å½±åƒè·¯å¾‘ä¸¦ç”ŸæˆåŒ…å«æ–‡ä»¶è·¯å¾‘å’Œæ¨™ç±¤çš„æ•¸æ“šæ¡†
```python
# å–å¾—æ‰€æœ‰åœ–ç‰‡çš„è·¯å¾‘
train_filepaths = get_image_filepaths('/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/03_æ°´æœ/train')
test_filepaths = get_image_filepaths('/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/03_æ°´æœ/test')
val_filepaths = get_image_filepaths('/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/03_æ°´æœ/validation')

def proc_img(filepaths):
    data = [] # å‰µå»ºä¸€å€‹ç©ºåˆ—è¡¨ï¼Œç”¨æ–¼å­˜å„²æ–‡ä»¶è·¯å¾‘å’Œæ¨™ç±¤
    for filepath in filepaths:
        label = filepath.parent.name # ç²å–æ–‡ä»¶è·¯å¾‘çš„çˆ¶ç›®éŒ„åç¨±(å³æ¨™ç±¤)
        data.append({'Filepath':str(filepath),'Label':label}) # å°‡æ–‡ä»¶è·¯å¾‘å’Œæ¨™ç±¤æ·»åŠ åˆ°dataåˆ—è¡¨ä¸­
    return pd.DataFrame(data)

# ç”Ÿæˆè¨“ç·´ã€æ¸¬è©¦å’Œé©—è­‰æ•¸æ“šæ¡†
train_df = proc_img(train_filepaths)
test_df = proc_img(test_filepaths)
val_df = proc_img(val_filepaths)
```



## 5.ç²å–å½±åƒæ¨™ç±¤ä¸¦è¨ˆç®—è³‡æ–™é›†åˆ†ä½ˆ
- å¾å½±åƒæª”æ¡ˆè·¯å¾‘ä¸­æå–æ¨™ç±¤ï¼Œä¸¦è¨ˆç®—è¨“ç·´ã€æ¸¬è©¦å’Œé©—è­‰è³‡æ–™é›†ä¸­æ¯å€‹æ¨™ç±¤çš„åˆ†ä½ˆæƒ…æ³
```python
# path.parent.name å¯ä»¥å–å¾—è³‡æ–™å¤¾åç¨±ï¼Œfilepaths æ˜¯ä¸€å€‹ list
train_labels = [path.parent.name for path in train_filepaths]
test_labels = [path.parent.name for path in test_filepaths]
val_labels = [path.parent.name for path in val_filepaths]

print('Training set distribution:',Counter(train_labels))
print('Testing set distribution:',Counter(test_labels))
print('Validation set distribution:',Counter(val_labels))
```
åŸ·è¡Œçµæœ:  
`Training set distribution: Counter({'soy beans': 92, 'peas': 90, 'spinach': 87, 'lettuce': 87, 'turnip': 85, 'grapes': 85, 'tomato': 84, 'pineapple': 84, 'cabbage': 84, 'beetroot': 84, 'corn': 84, 'sweetcorn': 83, 'garlic': 83, 'kiwi': 82, 'onion': 80, 'capsicum': 80, 'watermelon': 79, 'jalepeno': 79, 'cucumber': 78, 'bell pepper': 78, 'mango': 77, 'eggplant': 77, 'pear': 76, 'chilli pepper': 76, 'paprika': 74, 'pomegranate': 74, 'carrot': 73, 'cauliflower': 71, 'raddish': 70, 'sweetpotato': 69, 'potato': 66, 'ginger': 64, 'lemon': 64, 'banana': 62, 'orange': 61, 'apple': 58})`

`Testing set distribution: Counter({'sweetcorn': 10, 'tomato': 10, 'watermelon': 10, 'soy beans': 10, 'sweetpotato': 10, 'turnip': 10, 'spinach': 10, 'pear': 10, 'pineapple': 10, 'pomegranate': 10, 'paprika': 10, 'mango': 10, 'eggplant': 10, 'kiwi': 10, 'ginger': 10, 'cucumber': 10, 'corn': 10, 'garlic': 10, 'beetroot': 10, 'cabbage': 10, 'peas': 9, 'lettuce': 9, 'potato': 9, 'onion': 9, 'jalepeno': 9, 'bell pepper': 9, 'cauliflower': 9, 'apple': 9, 'capsicum': 9, 'banana': 9, 'raddish': 8, 'grapes': 8, 'orange': 7, 'lemon': 7, 'chilli pepper': 7, 'carrot': 7})`

`Validation set distribution: Counter({'watermelon': 10, 'spinach': 10, 'pomegranate': 10, 'sweetcorn': 10, 'turnip': 10, 'tomato': 10, 'soy beans': 10, 'sweetpotato': 10, 'paprika': 10, 'pear': 10, 'pineapple': 10, 'kiwi': 10, 'mango': 10, 'corn': 10, 'garlic': 10, 'ginger': 10, 'cucumber': 10, 'eggplant': 10, 'cabbage': 10, 'beetroot': 10, 'potato': 9, 'onion': 9, 'peas': 9, 'lettuce': 9, 'jalepeno': 9, 'cauliflower': 9, 'bell pepper': 9, 'apple': 9, 'capsicum': 9, 'banana': 9, 'raddish': 8, 'grapes': 8, 'orange': 7, 'lemon': 7, 'chilli pepper': 7, 'carrot': 7})`


## 6.é¡¯ç¤ºæ¯å€‹é¡åˆ¥çš„ç¬¬ä¸€å¼µåœ–åƒ
- å‰µå»ºä¸€å€‹å­—å…¸ä¾†å­˜å„²æ¯å€‹é¡åˆ¥çš„ç¬¬ä¸€å¼µå½±åƒï¼Œä¸¦ä½¿ç”¨ Matplotlib é¡¯ç¤ºé€™äº›å½±åƒ

```python
first_images = {}
for category in train_df['Label'].unique():
    first_images[category] = train_df[train_df['Label'] == category]['Filepath'].values[0]

plt.figure(figsize=(15,10))
for i, (category, image_path) in enumerate(first_images.items()):
    image = Image.open(image_path)
    plt.subplot(6,6,i+1) # i+1 æ˜¯å› ç‚º subplot å¾ 1 é–‹å§‹
    plt.imshow(image)
    plt.title(category)
    plt.axis('off')

plt.show()
```
åŸ·è¡Œçµæœ:  
![æ¯å€‹é¡åˆ¥](https://github.com/user-attachments/assets/0ae3f70b-f0c1-4c3d-a5bf-44a64d485514)




## 7.å‰µå»ºå½±åƒæ•¸æ“šç”Ÿæˆå™¨é€²è¡Œæ•¸æ“šå¢å¼·å’Œé è™•ç† 
```python
# ä½¿ç”¨ ImageDataGenerator é€²è¡Œæ•¸æ“šå¢å¼·

train_datagen = ImageDataGenerator(
    rescale=1./255, # å°‡åƒç´ å€¼ç¸®æ”¾åˆ° [0, 1] ä¹‹é–“
    rotation_range=40, # éš¨æ©Ÿæ—‹è½‰åœ–ç‰‡
    width_shift_range=0.2, # éš¨æ©Ÿæ°´å¹³å¹³ç§»
    height_shift_range=0.2, # éš¨æ©Ÿå‚ç›´å¹³ç§»
    shear_range=0.2, # éš¨æ©Ÿå‰ªåˆ‡(æ²¿æŸå€‹æ–¹å‘å‚¾æ–œ)
    zoom_range=0.2, # éš¨æ©Ÿç¸®æ”¾
    horizontal_flip=True, # éš¨æ©Ÿæ°´å¹³ç¿»è½‰
    brightness_range=[0.8, 1.2], # éš¨æ©Ÿèª¿æ•´äº®åº¦
    channel_shift_range=0.2, # éš¨æ©Ÿæ”¹è®Šé¡è‰²é€šé“
    fill_mode='nearest' # å¡«å……æ–°å‰µå»ºåƒç´ çš„æ–¹æ³•
)

# å‰µå»º ImageDataGenerator ç”¨æ–¼é©—è­‰å’Œæ¸¬è©¦æ•¸æ“šé›†ï¼ˆä¸é€²è¡Œå¢å¼·ï¼‰
test_datagen = ImageDataGenerator(rescale=1./255)

# å‰µå»ºæ•¸æ“šç”Ÿæˆå™¨
train_generator = train_datagen.flow_from_dataframe(
    train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224,224),
    batch_size=32,
    class_mode='categorical' # ä½¿ç”¨ categorical_crossentropy æå¤±å‡½æ•¸
)

val_generator = test_datagen.flow_from_dataframe(
    val_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224,224),
    batch_size=32,
    class_mode='categorical'
)

# åœ¨å‰µå»ºæ•¸æ“šç”Ÿæˆå™¨ä¹‹å‰æ‰“äº‚æ•¸æ“šæ¡†
test_df = test_df.sample(frac=1).reset_index(drop=True)

# é‡æ–°å‰µå»ºæ•¸æ“šç”Ÿæˆå™¨
test_generator = test_datagen.flow_from_dataframe(
    test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224,224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)
```
åŸ·è¡Œçµæœ:  
![æ•¸æ“šå¢å¼·](https://github.com/user-attachments/assets/59c89801-5472-4adc-8f58-25c0a7d6ea7d)




## 8.è¼‰å…¥ä¸¦é…ç½®é è¨“ç·´æ¨¡å‹ MobileNetV2
```python
# è¼‰å…¥é è¨“ç·´æ¨¡å‹
base_model = MobileNetV2(
    input_shape=(224,224,3), # è¼¸å…¥åœ–åƒçš„å½¢ç‹€
    include_top=False, # ä¸åŒ…å«é ‚å±¤çš„å…¨é€£æ¥å±¤
    weights='imagenet', # ä½¿ç”¨ ImageNet é è¨“ç·´æ¬Šé‡
    pooling='avg' # å…¨å±€å¹³å‡æ± åŒ–
)
base_model.trainable = False

# é¡¯ç¤ºæ¨¡å‹æ‘˜è¦
# base_model.summary()
```



## 9.å»ºç«‹ä¸¦è¨“ç·´å½±åƒåˆ†é¡æ¨¡å‹
```python
# å»ºç«‹æ¨¡å‹
input = base_model.input
x = layers.Dense(512,activation='relu')(base_model.output)
x = layers.Dense(256,activation='relu')(x)
x = layers.Dense(128,activation='relu')(x)
x = layers.Dense(64,activation='relu')(x)
output = layers.Dense(36,activation='softmax')(x)

model = models.Model(inputs=input,outputs=output)

# ç·¨è­¯æ¨¡å‹
model.compile(optimizer=optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# è¨­ç½®å›èª¿å‡½æ•¸
callbacks = [
    tf.keras.callbacks.ModelCheckpoint(
        filepath='/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/03_æ°´æœ/fruit_model.keras',
        save_best_only=True, # åªå„²å­˜æ€§èƒ½æœ€å¥½çš„æ¨¡å‹ï¼ˆæ ¹æ“šç›£æ§æŒ‡æ¨™ï¼‰
        monitor='val_accuracy', # ç›£æ§é©—è­‰é›†çš„æº–ç¢ºç‡
        mode='max' # ç•¶ val_accuracy æœ€å¤§æ™‚ï¼Œå„²å­˜æ¨¡å‹
    )
]

# è¨“ç·´æ¨¡å‹
history = model.fit(train_generator, # ä½¿ç”¨è¨“ç·´é›†æ•¸æ“š
                    validation_data=val_generator, # ä½¿ç”¨é©—è­‰é›†æ•¸æ“š
                    epochs=50,
                    callbacks=callbacks)
```
åŸ·è¡Œçµæœ:  
![è¨“ç·´](https://github.com/user-attachments/assets/2d5dc97d-1214-46fa-85df-953f4ad3aa80)




## 10.è¦–è¦ºåŒ–æ¨¡å‹è¨“ç·´éç¨‹ä¸­çš„æº–ç¢ºç‡å’Œæå¤±
- å°‡æ¨¡å‹è¨“ç·´éç¨‹ä¸­çš„æº–ç¢ºç‡å’Œæå¤±æ•¸æ“šè½‰æ›ç‚º DataFrame
- ä½¿ç”¨ Matplotlib ç¹ªè£½å‡ºè¨“ç·´å’Œé©—è­‰éç¨‹ä¸­çš„æº–ç¢ºç‡å’Œæå¤±æ›²ç·š 
```python
# å°‡è¨“ç·´æ­·å²è½‰æ›ç‚º DataFrame
result = pd.DataFrame(history.history)

# å‰µå»ºå­åœ–
fig, axes = plt.subplots(1,2,figsize=(15, 5))

# ç¹ªè£½æº–ç¢ºç‡æ›²ç·š
result[['accuracy','val_accuracy']].plot(ax=axes[0])
axes[0].set_title("Accuracy")
axes[0].set_xlabel("Epochs")
axes[0].set_ylabel("Accuracy")

# ç¹ªè£½æå¤±æ›²ç·š
result[['loss','val_loss']].plot(ax=axes[1])
axes[1].set_title("Loss")
axes[1].set_xlabel("Epochs")
axes[1].set_ylabel("Loss")

# èª¿æ•´ä½ˆå±€ä¸¦é¡¯ç¤ºåœ–è¡¨
plt.tight_layout()
plt.show()
```
åŸ·è¡Œçµæœ:  
![æº–ç¢ºç‡å’Œæå¤±](https://github.com/user-attachments/assets/e06b1f42-cd7d-4b66-938e-e72dffd4dd54)




## 11.ç²å–ä¸¦é¡¯ç¤ºæ¨™ç±¤å°æ‡‰è¡¨
```python
# ç²å–æ¨™ç±¤å°æ‡‰è¡¨
label_map = train_generator.class_indices

# åè½‰å­—å…¸ä»¥ä¾¿æ–¼æŸ¥è©¢
label_map = {v:k for k, v in label_map.items()}

# é¡¯ç¤ºæ¨™ç±¤å°æ‡‰è¡¨
print(label_map)
```
åŸ·è¡Œçµæœ:  
`{0: 'apple', 1: 'banana', 2: 'beetroot', 3: 'bell pepper', 4: 'cabbage', 5: 'capsicum', 6: 'carrot', 7: 'cauliflower', 8: 'chilli pepper', 9: 'corn', 10: 'cucumber', 11: 'eggplant', 12: 'garlic', 13: 'ginger', 14: 'grapes', 15: 'jalepeno', 16: 'kiwi', 17: 'lemon', 18: 'lettuce', 19: 'mango', 20: 'onion', 21: 'orange', 22: 'paprika', 23: 'pear', 24: 'peas', 25: 'pineapple', 26: 'pomegranate', 27: 'potato', 28: 'raddish', 29: 'soy beans', 30: 'spinach', 31: 'sweetcorn', 32: 'sweetpotato', 33: 'tomato', 34: 'turnip', 35: 'watermelon'}`



## 12.è¼‰å…¥æœ€ä½³æ¨¡å‹ä¸¦ä½¿ç”¨æ¸¬è©¦æ•¸æ“šé€²è¡Œé æ¸¬
```python
# è¼‰å…¥æœ€ä½³æ¨¡å‹
model = tf.keras.models.load_model('/content/drive/MyDrive/3.Pythonæ·±åº¦å­¸ç¿’æ‡‰ç”¨é–‹ç™¼/03_æ°´æœ/fruit_model.keras')

# ä½¿ç”¨æ¸¬è©¦æ•¸æ“šç”Ÿæˆå™¨é€²è¡Œé æ¸¬
test_loss,test_accuracy = model.evaluate(test_generator)
print(f'Test accuracy:{test_accuracy * 100:.2f}%')

# ç²å–é æ¸¬çµæœ
predictions = model.predict(test_generator)
predicted_classes = np.argmax(predictions,axis=1)

# é¡¯ç¤ºå‰10å€‹é æ¸¬çµæœå’Œå¯¦éš›çµæœ
predicted_labels = [label_map[i] for i in predicted_classes[:10]]
actual_labels = [label_map[i] for i in test_generator.classes[:10]]

print("Predicted labels:",predicted_labels)
print("Actual labels:",actual_labels)
```
åŸ·è¡Œçµæœ:  
![æ¸¬è©¦é æ¸¬](https://github.com/user-attachments/assets/6146212c-e4a0-418e-b561-77953b6626f2)




## 13.é¡¯ç¤ºæ··æ·†çŸ©é™£
- è©•ä¼°æ¨¡å‹åœ¨æ¸¬è©¦æ•¸æ“šä¸Šçš„é æ¸¬æ•ˆæœ
```python
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

true_classes = test_generator.classes
pred_classes = predicted_classes

# ç”¢ç”Ÿæ··æ·†çŸ©é™£
cm = confusion_matrix(true_classes,pred_classes)

# é¡¯ç¤ºæ··æ·†çŸ©é™£
fig,ax = plt.subplots(figsize=(15,10))
disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=test_generator.class_indices.keys())
disp.plot(cmap=plt.cm.Blues,ax=ax)

# è‡ªå®šç¾©åœ–å½¢
plt.xticks(rotation=90)  # æ—‹è½‰ x è»¸æ¨™ç±¤ä»¥æé«˜å¯è®€æ€§
plt.title('Confusion Matrix')
plt.show()
```

åŸ·è¡Œçµæœ:  
![æ··æ·†çŸ©é™£](https://github.com/user-attachments/assets/e70ace2b-7764-4032-bfbf-a5b850e710a1)




## 14.Hugging Face Spaces æ‡‰ç”¨
- æœ¬å°ˆæ¡ˆçš„ Streamlit æ‡‰ç”¨å·²æˆåŠŸéƒ¨ç½²è‡³ Hugging Face Spaces 
- ä½ å¯ä»¥é€éä»¥ä¸‹é€£çµç›´æ¥ä½¿ç”¨æ‡‰ç”¨ï¼š[é»æ­¤é€²å…¥](https://huggingface.co/spaces/CR7-800/fruit-image-classification)    
![è¾¨è­˜](https://github.com/user-attachments/assets/14953dea-faac-4738-90aa-4a7aeb258555)






## 15.çµè«–
åœ¨æœ¬å°ˆæ¡ˆä¸­ï¼Œæˆ‘å€‘æˆåŠŸåœ°å»ºç«‹äº†ä¸€å€‹åŸºæ–¼ `MobileNetV2` çš„å·ç©ç¥ç¶“ç¶²çµ¡æ¨¡å‹ï¼Œç”¨æ–¼è¾¨è­˜æ°´æœå’Œè”¬èœçš„åœ–åƒã€‚  
é€šéæ•¸æ“šå¢å¼·å’Œé è™•ç†ï¼Œæœ‰æ•ˆåœ°æå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚  
è¨“ç·´éç¨‹ä¸­ï¼Œä½¿ç”¨ `Kaggle` ä¸Šçš„ `Fruits and Vegetables Image Recognition Dataset`ï¼Œä¸¦åœ¨ `Google Colab` ä¸Šé€²è¡Œäº†æ¨¡å‹è¨“ç·´ã€‚

æ¨¡å‹åœ¨æ¸¬è©¦æ•¸æ“šé›†ä¸Šçš„æº–ç¢ºç‡é”åˆ°äº†ä»¤äººæ»¿æ„çš„æ°´å¹³ï¼Œä¸¦ä¸”é€šéæ··æ·†çŸ©é™£ï¼Œå¯ä»¥çœ‹åˆ°æ¨¡å‹åœ¨ä¸åŒé¡åˆ¥ä¸Šçš„é æ¸¬æ•ˆæœã€‚ 

æœªä¾†çš„æ”¹é€²æ–¹å‘å¯ä»¥åŒ…æ‹¬ï¼š
1. æ¢ç´¢å…¶ä»–é è¨“ç·´æ¨¡å‹ï¼Œå¦‚ EfficientNet æˆ– ResNetï¼Œä»¥é€²ä¸€æ­¥æå‡æ¨¡å‹æ€§èƒ½ã€‚
2. å¢åŠ æ•¸æ“šé›†çš„å¤šæ¨£æ€§ï¼ŒåŒ…å«æ›´å¤šä¸åŒèƒŒæ™¯å’Œå…‰ç…§æ¢ä»¶ä¸‹çš„åœ–åƒã€‚
3. å„ªåŒ–æ¨¡å‹è¶…åƒæ•¸ï¼Œé€²ä¸€æ­¥æå‡æº–ç¢ºç‡å’Œé™ä½æå¤±ã€‚
